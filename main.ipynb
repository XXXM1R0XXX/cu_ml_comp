{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from dataclasses import dataclass\n",
    "from simple_parsing import parse\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    train_path: str = \"data/train.parquet\"\n",
    "    test_path: str = \"data/test.parquet\"\n",
    "    ssub_path: str = \"data/sample_submission.csv\"\n",
    "    sub_path: str = \"submission.csv\"\n",
    "\n",
    "args = parse(Args)\n",
    "\n",
    "SEED = 228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(args.train_path, engine=\"fastparquet\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(args.test_path, engine=\"fastparquet\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(len(train) * 0.8)\n",
    "\n",
    "train_df = train.iloc[:split_idx]\n",
    "val_df = train.iloc[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(\n",
    "    data=train_df.drop([\"a6_flg\"], axis=1),\n",
    "    label=train_df[\"a6_flg\"],\n",
    "    cat_features=[\"product\"],\n",
    "    timestamp=train_df[\"month_dt\"],\n",
    ")\n",
    "val_pool = Pool(\n",
    "    data=val_df.drop([\"a6_flg\"], axis=1),\n",
    "    label=val_df[\"a6_flg\"],\n",
    "    cat_features=[\"product\"],\n",
    "    timestamp=val_df[\"month_dt\"],\n",
    ")\n",
    "full_train_pool = Pool(\n",
    "    data=train.drop([\"a6_flg\"], axis=1),\n",
    "    label=train[\"a6_flg\"],\n",
    "    cat_features=[\"product\"],\n",
    "    timestamp=train[\"month_dt\"],\n",
    ")\n",
    "test_pool = Pool(data=test, cat_features=[\"product\"], timestamp=test[\"month_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        \"eval_metric\": \"AUC\",\n",
    "        \"task_type\": \"GPU\",\n",
    "        \"verbose\": False,\n",
    "        \"random_seed\": SEED,\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"use_best_model\": True,\n",
    "        \"boosting_type\": \"Plain\",\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 2000, 5000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.3, log=True),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-2, 10.0, log=True),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 1e-9, 10.0, log=True),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 32, 254),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "    }\n",
    "\n",
    "    grow_policy = trial.suggest_categorical(\"grow_policy\", [\"SymmetricTree\", \"Depthwise\", \"Lossguide\"])\n",
    "    param[\"grow_policy\"] = grow_policy\n",
    "\n",
    "    if grow_policy == \"SymmetricTree\":\n",
    "        param[\"depth\"] = trial.suggest_int(\"depth\", 2, 10)\n",
    "    elif grow_policy == \"Depthwise\":\n",
    "        param[\"depth\"] = trial.suggest_int(\"depth\", 4, 12)\n",
    "    elif grow_policy == \"Lossguide\":\n",
    "        param[\"max_leaves\"] = trial.suggest_int(\"max_leaves\", 16, 64)\n",
    "        param[\"depth\"] = trial.suggest_int(\"depth\", 4, 12)\n",
    "\n",
    "    bootstrap_type = trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\"])\n",
    "    param[\"bootstrap_type\"] = bootstrap_type\n",
    "\n",
    "    if bootstrap_type == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    elif bootstrap_type == \"Bernoulli\":\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1.0)\n",
    "\n",
    "    auto_class_weights = trial.suggest_categorical(\"auto_class_weights\", [\"None\", \"Balanced\", \"SqrtBalanced\"])\n",
    "    if auto_class_weights != \"None\":\n",
    "        param[\"auto_class_weights\"] = auto_class_weights\n",
    "\n",
    "    model = CatBoostClassifier(**param)\n",
    "\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=val_pool,\n",
    "        verbose=0,\n",
    "        early_stopping_rounds=200\n",
    "    )\n",
    "\n",
    "    return model.get_best_score()[\"validation\"][\"AUC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=50, timeout=600)\n",
    "\n",
    "print(f\"Best trial found: {study.best_value}\")\n",
    "print(f\"Params: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params.copy()\n",
    "\n",
    "best_params.update({\"eval_metric\": \"AUC\", \"task_type\": \"GPU\", \"random_seed\": SEED})\n",
    "\n",
    "final_model = CatBoostClassifier(**best_params)\n",
    "\n",
    "final_model.fit(full_train_pool, verbose=100, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_sub = pd.read_csv(args.ssub_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_sub[\"a6_flg\"] = final_model.predict_proba(test_pool)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_sub.to_csv(args.sub_path, index=False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
